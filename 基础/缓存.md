# 缓存常见问题

## Cache Aside 模式

1. DB 边上 配一个缓存集群 
2. 读数据 先读 缓存， 缓存没有就回源到 DB 查询，查到结果 就把数据put 到缓存 （读链路简单）
3. 写数据时，精卫监听db变更，主动失效缓存。（有时序问题可能到时缓存数据和db数据不一致。 有一种方式是定期全量更新db某个非业务字段，如updateTime，触发binlog，全量更新一遍缓存，来尽量修复错误缓存数据）。
4. 缓存不和业务耦合：
   1. 查db，使用Spring-Cache的 @Cacheable 注解 做到自动put数据到缓存。
   2. 删除缓存只要是依靠 binlog，在业务外的之路（其他应用）上做。

## 缓存穿透（cache & db 都无该key）

​		**概念**：用户需要查询一个数据，缓存中没有，也就是没有命中，于是向数据库中发起请求，发现也没有。当用户很多的时候，缓存都没有命中，于是都去请求数据库，这给数据库造成很大的压力。

​		**解决方案**：

- 布隆过滤器：是一种数据结构，**处理的场景： 大数据量集合，如何准确快速的判断某个数据是否在** 。    [布隆过滤器](https://www.cnblogs.com/ysocean/p/12594982.html) ， 有些客户端都自带的，不需要手动从0写。 如 Redisson，guava 都有线程的 BloomFilter
- 缓存空对象：当存储层没有命中时，即使返回空对象也将其缓存起来。（意味着更多的空间存储，即使设置了过期时间，缓存和数据库还是有段时间数据不一致。）

## 缓存击穿（cache无，db有）

​		**概念**：当一个 key 非常热点时，在不断扛高并发，集中对这个热点数据进行访问，当这个 key 失效的瞬间，请求直接到达数据库，给数据库瞬间的高压力。

​		**解决方案**：

- 设置热点数据永不过期
- 加分布式锁：保证每个 key 同时只有一个线程去查询后端服务。

## 缓存雪崩

​		**概念**：某个时间段，缓存集中失效。 和缓存击穿区别：雪崩是大量的key 失效，击穿是扛高并发的key突然失效。（Cache avalanche is a scenario where **lots of cached data expire at the same time** ）

​		**解决方案**：

- 增加 Redis 集群的数量
- 缓存过期时间的时候，错峰设置
- 限流降级：在缓存失效后，通过加锁和队列来控制数据库写缓存的线程数量
- 数据预热：正式部署之前，将数据预先访问一遍，让缓存失效的时间尽量均匀



## 缓存击穿（Cache没数据，db有数据）

​		热点key失效，同时有大量请求该key的请求，都打到db，导致db压力飙升

> 解决办法：
>
> 1. 热点数据不要失效
> 2. N多个线程同时请求一个key时，加锁访问，只有一个请求会去访问db并更新缓存

## 缓存雪崩

​		某一时刻大量缓存同时失效，导致db流量飙升打挂db。

> 解决办法：
>
> 1. 限流拒绝服务，让一部分用户可用，其他用户排队进入服务
> 2. 



##  缓存热点

​		大卖家数据，导致N多请求查询该卖家（微博明信，热点微博等）。导致大量请求（同一个key）hash到同一台缓存服务器，缓存单机被打爆。

> 解决办法：
>
> 1. 最简单粗暴的方法是限流。 tair客户端直接限流了。 压测时达到15w qps，客户端又限流日志。
> 2. 本地缓存。探测出热key之后，本地缓存一份，流量就分散到服务机器上。 问题是有一定数据不一致。
> 3. 拆 key。big_seller_key_01, big_seller_key_02 ...  这样分成8个key，然后对每个请求出一个hash值，对8取余来均匀分散请求到不同的key
> 4. 开源工具，京东hotkey： 原理就是在client端做洞察，然后上报对应hotkey，server端检测到后，将对应hotkey下发到对应服务端做本地缓存，并且这个本地缓存在远程对应的key更新后，会同步更新。 就是方法2且另外保证了本地缓存的准确性。
> 5. 



## 缓存预热

​		如应用刚启动，缓存刚启动，某些活动场景，防止开始服务时大量请求过来，数据首次被访问，回源db，把db打挂。可以考虑先将热点数据刷入到缓存中，再开始提供对外服务。